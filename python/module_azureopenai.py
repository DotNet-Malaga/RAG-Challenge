import re
import os
import subprocess
from datetime import datetime, timedelta
import psycopg2
from psycopg2 import sql
import pandas as pd
from openai import AzureOpenAI

def get_script(endpoint, api_key, deployment_name, temperature, content, prompt):

    client = AzureOpenAI(
    azure_endpoint=endpoint,
    api_key=api_key,
    api_version="2023-05-15"
    )

    response = client.chat.completions.create(
    model=deployment_name,
    messages=[
        {"role": "system", "content": content},
        {"role": "user", "content": prompt},
    ],
    temperature=temperature,  # Reduce la creatividad
    max_tokens=150,  # Limita la longitud de la respuesta
    )
    # Get the response generated by the model
    output = response.choices[0].message.content

    # Reemplaza saltos de lÃ­nea dobles con uno solo
    output = output.replace('\n\n', '\n').replace('\n\n', '\n')

    return output


def get_events_fromDB (server, database, username, password, match_id):

      # Connect to the database
    conn = psycopg2.connect(
        host=server,
        database=database,
        user=username,
        password=password
    )
    
    cursor = conn.cursor()

    sql = f"""
            select json_
            from events_details
            where match_id = '{match_id}'
            order by period, timestamp;
            """    
    cursor.execute(sql)

    # Convert the result to a dataframe
    df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])

    return df

if __name__ == "__main__":

    # Example usage
    ollama = os.getenv('PATH_OLLAMA')
    cabecera = os.getenv('MESSAGE_HEADER')

    server = os.getenv('DB_SERVER')
    database = os.getenv('DB_NAME')
    username = os.getenv('DB_USER')
    password = os.getenv('DB_PASSWORD')
    dir_destino = os.getenv('DIR_DESTINO')
    dir_destino = os.path.join(dir_destino, "scripts")

    openai_model = os.getenv('OPENAI_MODEL')
    openai_key = os.getenv('OPENAI_KEY')
    openai_endpoint = os.getenv('OPENAI_ENDPOINT')
    openai_temperature = float(os.getenv('OPENAI_TEMPERATURE', 0.1))

    match_id = 3943043
    rows_per_batch = 50
    start_time = datetime.now()

    file_batch_size = 10
    num_files_in_batch = 0
    num_file = 0
    in_batch=True
    script=""

    df = get_events_fromDB(server, database, username, password, match_id)
    count = df.shape[0]

    # calculate the number of files to generate
    total_num_files = count // (rows_per_batch * file_batch_size)
    if count % (rows_per_batch * file_batch_size) > 0:
        total_num_files += 1

    # Loop from_time to to_time with batch_size increment
    i=2950
    while i < count:
        batch_start_time = datetime.now()
        num_files_in_batch += 1

        # Put the subset of df from i to i+rows_count in df_batch
        df_batch = df.iloc[i:i+rows_per_batch]
        df_text = df_batch.to_string(index=False)

        # Get transcript with openAI
        prompt = f"{cabecera}: {df_text}"

        script += get_script(openai_endpoint, openai_key, openai_model, openai_temperature, cabecera, df_text)

        # print batch processing time withouth miliseconds
        time = datetime.now() - batch_start_time
        time_str = str(time).split(".")[0]
        print(f"Batch processing time {num_files_in_batch}/{file_batch_size}: {time_str} ", end="")

        time = ((datetime.now() - start_time) / (i+1)) * (count - i)
        time_str = str(time).split(".")[0]
        # Print the elapsed time and the remaining time
        print(f"Estimated remaining time: {time_str}")

        if num_files_in_batch == file_batch_size:
            num_files_in_batch = 0
            in_batch = False
            num_file += 1

            # Save script to file with this format: <match_id>-i.txt where i is a numeric value starting from 0 and occupying 6 positions
            filename = f"{match_id}-{str(num_file).zfill(6)}-{str(total_num_files).zfill(6)}.txt"
            with open(os.path.join(dir_destino, filename), "w", encoding="utf-8") as f:
                f.write(script)

            # Print the generated file path, the number of processed rows, and the number of pending rows
            print(f"  Processed {i+1}/{count} rows. Generated file: {filename}. ")
            script=""

        i+=rows_per_batch

    if in_batch:
        num_file += 1
        filename = f"{match_id}-{str(num_file).zfill(6)}-{str(total_num_files).zfill(6)}.txt"
        with open(os.path.join(dir_destino, filename), "w", encoding="utf-8") as f:
            f.write(script)

        # Print the generated file path, the number of processed rows, and the number of pending rows
        print(f"  Processed {i+1}/{count} rows. Generated file: {filename}. ")
        script=""