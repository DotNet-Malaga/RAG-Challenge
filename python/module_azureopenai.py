import os
import subprocess
from datetime import datetime, timedelta
import psycopg2
from psycopg2 import sql
import pandas as pd
from openai import AzureOpenAI

def get_script(endpoint, api_key, deployment_name, content, prompt):

    client = AzureOpenAI(
    azure_endpoint=endpoint,
    api_key=api_key,
    api_version="2023-05-15"
    )

    response = client.chat.completions.create(
    model=deployment_name,
    messages=[
        {"role": "system", "content": content},
        {"role": "user", "content": prompt},
    ]
    )
    # Get the response generated by the model
    output = response.choices[0].message.content
    return output.encode('utf-8').decode('utf-8')


def get_events_fromDB (server, database, username, password, match_id):

      # Connect to the database
    conn = psycopg2.connect(
        host=server,
        database=database,
        user=username,
        password=password
    )
    
    cursor = conn.cursor()

    sql = f"""
            select json_
            from events_details
            where match_id = '{match_id}'
            order by period, timestamp;
            """    
    cursor.execute(sql)

    # Convert the result to a dataframe
    df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])

    return df

if __name__ == "__main__":

    # Example usage
    ollama = os.getenv('PATH_OLLAMA')
    cabecera = os.getenv('MESSAGE_HEADER')

    server = os.getenv('DB_SERVER')
    database = os.getenv('DB_NAME')
    username = os.getenv('DB_USER')
    password = os.getenv('DB_PASSWORD')
    dir_destino = os.getenv('DIR_DESTINO')
    dir_destino = os.path.join(dir_destino, "scripts")

    openai_model = os.getenv('OPENAI_MODEL')
    openai_key = os.getenv('OPENAI_KEY')
    openai_endpoint = os.getenv('OPENAI_ENDPOINT')

    match_id = 3943043
    rows_count = 10
    start_time = datetime.now()

    df = get_events_fromDB(server, database, username, password, match_id)
    count = df.shape[0]

    # Loop from_time to to_time with batch_size increment
    for i in range(0, count):

        batch_start_time = datetime.now()

        # Put the subset of df from i to i+rows_count in df_batch
        df_batch = df.iloc[i:i+rows_count]
        df_text = df_batch.to_string(index=False)

        # Get transcript with openAI
        prompt = f"{cabecera}: {df_text}"

        script = get_script(openai_endpoint, openai_key, openai_model, cabecera, df_text)

        # Save script to file with this format: <match_id>-i.txt where i is a numeric value starting from 0 and occupying 6 positions
        filename = f"{match_id}-{str(i+1).zfill(6)}.txt"
        with open(os.path.join(dir_destino, filename), "w") as f:
            f.write(script)

        # Print the generated file path, the number of processed rows, and the number of pending rows
        print(f"Processed {i+rows_count}/{count - i - rows_count} rows. Generated file: {filename}. ", end="")

        # print batch processing time withouth miliseconds
        time = datetime.now() - batch_start_time
        time_str = str(time).split(".")[0]
        print(f"Batch processing time: {time_str} ", end="")

        time = (datetime.now() - start_time) / (i+rows_count) * (count - i - rows_count)
        time_str = str(time).split(".")[0]
        # Print the elapsed time and the remaining time
        print(f"Estimated remaining time: {time_str}")
